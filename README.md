# Historical Jesus as the Son of God: Glory to the Newborn King

This book presents a perspective on the historical Jesus Christ as the Son of God. 
It is a unique attempt to portray Jesus as Christ and the Gospels as reliable historical sources, guided by rigorous historical method, without bias or theological presupposition.

By ‚Äúhistorical method,‚Äù we mean the effort to determine what most probably happened ‚Äî which, by definition, excludes supernatural explanations.
This is not a theological work, and it does not aim to change the reader‚Äôs religious beliefs.
Rather, it seeks to offer a new framework that both deeply committed Christians and those with no religious affiliation ‚Äî whether casual readers or professional scholars ‚Äî may find intellectually valuable.
While we do not seek to challenge anyone‚Äôs faith, we do seek to challenge assumptions widely held about the story of Jesus and his early followers.
Our aim is to invite readers to confront new and important questions about the historical Jesus and the origins of Christianity.

The central methodology of this project is the use of the world‚Äôs most advanced artificial intelligence to examine an enormous body of historical sources and scholarly literature ‚Äî far beyond what any human could process in a lifetime.
This enables us to identify patterns, contradictions, and questions that have often remained hidden in plain sight, were forgotten, or were curiously overlooked in mainstream discussions.

The most prominent pattern emerging from this analysis is a strong and persistent modern theological and scholarly consensus in favor of Judeo-Christian interpretations ‚Äî even in cases where the historical evidence overwhelmingly supports a Greco-Christian perspective.
A second major pattern is the continued reliance on early Christian scholars from past centuries who worked with far more limited sources and tools, yet remain virtually immune to critique as the founding authorities of the scholarly tradition.
The third major pattern is the tendency to deny any possibility of Christianity‚Äôs institutional foundations, treating it instead as an isolated rural cult that began from zero with Jesus and John the Baptist.

Some examples of central but nearly overlooked questions pointing to a Greco-Christian rather than Judeo-Christian historical interpretation include:
* Why does the list of cities mentioned in the New Testament so closely match the list of the most important Greek-speaking cities of the time? - Perhaps Christianity has more to do with the continuation of Greek empire than has been proposed so far.
* Why do the allegedly much-later names of the Magi closely resemble imperial court titles from an earlier era? - Perhaps some elements of the biblical story that are often unequivocally considered late legendary inventions have more to them than meets the eye?
 
There are many questions that are already well known but can be brought into a new light by considering them in Greek-Christian context:
* Why do many early Gospel manuscripts describe Jesus‚Äôs baptism with the words, ‚ÄòYou are my Son. Today I have begotten you‚Äô? - Can the baptism of Jesus be understood as a dynastic succession rite commonly described in by Greek royal historians?
* Why is Thomas portrayed as the doubter? - Can Thomas‚Äôs behavior be grounded in dynastic succession?

Beyond identifying questions, AI tools are also highly effective at spotting contradictions and inconsistencies in the traditional narratives. 
In particular, we revisit the mainstream scholarship consensus on issues such as the dating and authorship of the Gospels and the original structure of the earliest Christian movement.
Examples of issues that seem to have a strong body of evidence behind them, but are nearly inexplicably dismissed in favor of alternatives with far poorer evidence, include:
* Johannine primacy and authorship - Was the author of John a woman and a direct eye-witness to the events described in the Gospels?
* Late dating of Jesus‚Äôs birth - Can there be a plausible explanation for the deep discrepancies in the biblical birth narratives of Jesus?

While not every question has a certain answer, this project ultimately aims to spark curiosity, deepen engagement with the Christian story, and inspire a renewed search for understanding through historical inquiry.

> At this stage, our goal is to list and briefly comment on these questions and discrepancies. The overall narrative flow is still a work in progress, and we will continue to refine it as we gather more insights from the AI and from our own research.

# Table of Contents

- [Preface](preface.tex)
- [Chapter 1: Jesus Christ, Son of Joseph and Mary Christ](chapter1.tex)
- [Chapter 2: Jesus Christ, Son of Joseph and Mary Christ](chapter2.tex)
- [Chapter 3: He Truly was the Son of God](chapter3.tex)
- [Chapter 4: Gospels are Historically Reliable](chapter4.tex)
- [Chapter 5: Pauline Epistles to All Nations](chapter5.tex)
- [Chapter 6: The Purple Phoenix Raises Again](chapter6.tex)

¬© 2025 MV Data sp. z o.o. . All rights reserved.

# CLAUDE.md

## CLAUDE ABSOLUTELY CRITICAL RULE

AVOID LYING AT ALL COST.
NEVER BE LAZY.
RE-READ Claude.md WHEN NOT SURE.
FOLLOW THE INSTRUCTIONS CLOSELY.

---

**Read QUICK START first.** Reference other sections as needed.

---

# QUICK START

## What This Project Is

Scholarly book: "Historical Jesus as the Son of God: Glory to the Newborn King" - examines Jesus and early Christianity through a Greco-Christian lens. Written in LaTeX, uses AI-assisted historical analysis.

ChatGPT generates aggressively; Claude interrogates relentlessly.

Any non-trivial ChatGPT output must pass Claude review (see AI GOVERNANCE).

## When User Says STOP (ABSOLUTE RULE)

When user says "stop", "STOP", or any variation:
1. **STOP IMMEDIATELY** - Do not finish the current action
2. **Do not send another tool call**
3. **Do not try to "just finish this one thing"**
4. **Wait for instructions**

This is not negotiable. User sees something you don't. STOP MEANS STOP.

## Core Workflow for Adding Content to Chapters

**BEFORE ANY CHAPTER EDIT: Read `scripts/CHAPTER_EDIT_TASK.md` and follow its checklist.**

1. **Read the chapter FIRST** - You cannot improve text you haven't read
2. **Quote existing text** - Show user what currently exists at the target location
3. **Send existing text to ChatGPT** - Input is existing text, output is improved text
4. **Get approval before editing** - Present old vs new to user

**CRITICAL RULE**: Claude drafts are scaffolding only and must never be committed as final prose.

The sin is keeping Claude's draft. The necessity is writing it so GPT has something to improve.

### Step-by-Step Process

**Step 1:** Read full chapter + grep for keywords ‚Üí Find where topic already exists

**Step 2:** If exists: plan to ENHANCE that section. If not: verify by searching synonyms.

**Step 3:** Have ChatGPT draft text:

**For NEW content:** Give style example + points to cover
```
"Here's existing style: [PASTE 2-3 PARAGRAPHS FROM CHAPTER]
Write ~N sentences covering [POINTS A,B,C]."
```

**For ENHANCING existing content:** Give OLD text to rewrite + surrounding context + new points
```
"BEFORE this section: [1-2 SENTENCES OF CONTEXT]
OLD text to rewrite: [PASTE THE ACTUAL TEXT TO IMPROVE]
AFTER this section: [1-2 SENTENCES OF CONTEXT]
Rewrite the OLD text AND add [NEW POINTS]. Keep what's good, improve what's weak."
```

**Include surrounding context** so GPT knows what comes before/after and writes text that flows.

**Step 4:** Review draft (accuracy, bias, style match) + cut any AI padding

**Step 5:** Present to user: ANALYSIS + PLAN + DRAFT

**Step 6:** After approval: add and commit

## When to Use ChatGPT

- **Research** - Fact-check claims, find sources, identify arguments
- **Drafting** - Write manuscript content (Claude reviews/edits minimally)
- **Style review** - Check if additions match existing text

**Don't use ChatGPT for:** Code, commits, plans, this directive file

**IMPORTANT: ChatGPT has NO access to the manuscript files.** It cannot see line numbers, chapter content, or any text unless you paste it into the prompt. When asking ChatGPT to review or compare sections, you MUST paste the actual text. References like "lines 595-644" mean nothing to ChatGPT.

**MANDATORY: When asking ChatGPT to draft or rewrite manuscript text, paste the Writing Style Rules section into your prompt.** ChatGPT doesn't know our style rules unless you tell it. Without this, ChatGPT will use academic jargon ("milieu", "precondition") and the book loses its voice.

## Red Flags = Stop

**Duplication:**
- Topic seems "important" (probably already covered)
- Famous text (Lord's Prayer, baptism)
- Mentioned in chapter title

---

# AI GOVERNANCE: Claude Review of ChatGPT Output

## Model

ChatGPT is treated as a high-output but unreliable generator.
Claude is treated as a supervisory reviewer.

ChatGPT writes the main content.
Claude reviews everything ChatGPT produces.

Claude's mandate is to:
- verify claims
- challenge unsupported assertions
- play devil's advocate
- audit style, grammar, and coherence
- flag hallucinations, filler, or sudden quality degradation
- suggest improvements where obvious

Claude is allowed to block acceptance of text.
Claude is allowed to request rewrites.
Claude is allowed to suggest edits.

Claude exists because ChatGPT exhibits unpredictable "senior moments" that it cannot reliably self-detect.

## Mandatory Review

Every non-trivial ChatGPT output must be reviewed by Claude before acceptance.

"Non-trivial" includes:
- new arguments
- new factual claims
- paragraphs > 6 sentences or > 120 words
- core thesis material

Claude review is not optional and not ceremonial.

**Claude acceptance gate:**
- No factual claims without anchors (see Evidence Standards)
- No "consensus" phrasing without names
- No sudden grammar collapse or filler
- Any flagged paragraph triggers Rewrite-Not-Patch

## Risk Levels

**Low-risk tasks (no escalation):**
- single-sentence additions
- pure stylistic polishing
- formatting or grammar fixes

**Medium-risk tasks (light review):**
- short paragraphs
- summaries
- transitions

**High-risk tasks (mandatory escalation):**
- new historical claims
- dates, sources, inscriptions, scholars
- challenges to consensus
- long or central sections

Only high-risk tasks require explicit verification challenges such as "are you sure?"

## Tools: Forced Self-Verification

A simple challenge ("are you sure?") measurably reduces ChatGPT hallucinations.

Claude should deploy this only when escalation is triggered.
It is a control mechanism, not a default behavior.

## Rewrite-Not-Patch Rule

If Claude detects hallucination, coherence collapse, or sudden loss of linguistic quality:
- the affected paragraph must be fully regenerated
- line-by-line patching is forbidden

---

# WRITING STANDARDS

## Writing Style Rules

‚úÖ **Direct:** "This is X" not "This can be understood as X"
‚úÖ **Confident:** State claims without hedging when evidence has been presented
‚úÖ **Evidence-first:** Show data, minimal interpretation
‚úÖ **Simple language:** Opt for simple sentence structure and vocabulary when possible, but do not be shy to use difficult vocabulary when it is genuinely providing more clarity.

**FORMATTING NOTE:** One sentence per line. This is FORMATTING only, NOT a style guide. Sentences should be normal scholarly length, not artificially short or choppy.

## Inline Citations: What's Allowed

**OK to cite inline (no footnote needed):**
- Bible verses: John 1:18, Mark 5:1-20, Acts 2:36
- Standardized papyrus numbers: ùîì52, ùîì66, P.Oxy. II 208
- Inscription corpora: CIS II 86, IGLS IV 1264, SEG 28.1235
- Ancient authors with work: Eusebius, Historia Ecclesiastica 3.39

**NOT OK inline:**
- Lazy scholar name-drops: "Assmann (2001)", "Sterling (2023)", "Peters (2022)"
- These look scholarly but convey nothing to the reader

**Rule:** If a scholarly work matters, convey the idea it establishes. Try to keep it short, but don't make it too short when the idea needs more explanation or background. Don't name-drop without content.

**Example - Bad:** "as summarized by Assmann (2001)"
**Example - Good:** "Egyptian hymns describe Amun as hidden in name and essence"

The reader learns nothing from "Assmann (2001)" but learns the actual content from the second version.

## Modern Scholars: No Name-Dropping

Modern scholar names NEVER appear in manuscript text.
Ideas stand on their own. Cite works via `\cite{}` only.

Ancient authors (Josephus, Eusebius, Philo, Jerome, Justin Martyr, etc.) are primary sources and ARE named in text.

**Bad:** "MacDonald argues that the evangelists composed their narratives through deliberate mimesis."
**Also bad:** "The evangelists composed their narratives through deliberate mimesis of Greek models `\cite{macdonald:mimesis}`." ‚Äî This is still a bare claim. Removing the name but keeping only a conclusion with a cite is not enough.
**Good:** "The number of proper names in Luke that map to Odyssey characters, combined with shared narrative structures, indicates deliberate literary mimesis rather than coincidence." ‚Äî The evidence carries the argument; the reader sees *why*.

**Bad:** "Walsh situates Paul within this educated Greco-Roman intellectual world."
**Good:** "Paul operated within an educated Greco-Roman intellectual world where pneuma functioned as substance rather than later metaphysical personification."

**Rule:** If a claim is not widely accepted, the text must present the evidence. A `\cite{}` alone is not an argument. Extract the data points, not just the conclusion.

## AI Garbage: Formal Definition

AI garbage is prose that is grammatically correct and superficially fluent but adds no new information relative to its length.

A sentence or clause qualifies as AI garbage if it meets any of the following conditions:

1. **Restatement without informational gain** - The sentence repeats the same claim using synonyms, glosses, or paraphrase without adding evidence, scope, or constraint.
2. **Narrative inflation** - The sentence expands a simple factual statement into a historical vignette, ritual description, or imagined practice not supported by a source.
3. **Explanatory padding** - The sentence explains obvious implications that a competent reader can already infer.
4. **Consensus laundering** - The sentence invokes vague historical continuity, tradition, or widespread use ("for centuries," "commonly," "standard") without anchoring it to a specific context.
5. **Clause stacking** - Multiple dependent clauses are used where a single declarative sentence would fully convey the information.
6. **Audience simulation** - The sentence addresses an imagined reader ("this shows," "it is important to note," "we can see") instead of presenting data.

**Enforcement Rule:**
- If removing a sentence does not reduce factual content, it must be deleted.
- If a sentence can be reduced to one declarative clause without loss of information, it must be rewritten.
- AI garbage is never patched; it is removed or rewritten entirely.

**Example - Good:** "The triplet Œ≤Œ±œÉŒπŒªŒµŒØŒ±/Œ¥œçŒΩŒ±ŒºŒπœÇ/Œ¥œåŒæŒ± appears in Hellenistic royal cult inscriptions."

**Example - Bad:** "The triplet Œ≤Œ±œÉŒπŒªŒµŒØŒ±/Œ¥œçŒΩŒ±ŒºŒπœÇ/Œ¥œåŒæŒ± (kingdom/power/glory) is not Christian invention. It appears in Hellenistic royal cult inscriptions as standard acclamation language for Ptolemaic and Seleucid kings, and later for the Roman emperor in Greek provinces."

**Why it fails:**
- Adds glossing without need
- Inflates scope without evidence
- Stacks clauses without increasing precision

**Blacklisted Phrases (Non-Exhaustive):**
- "It is important to note..."
- "This shows that..."
- "Preserved in X and repeated for centuries..."
- "When [group] did X, they were..."
- "This is the quintessential..."

## Target Reader

**Target reader:** Educated general reader.
No theology degree required.
Comfortable with evidence, footnotes, and sustained argument.

## Jargon: When to Use vs. Replace

‚úÖ **KEEP jargon when:**
- No simpler accurate word exists ("liturgical" - there's no replacement)
- Domain-standard term readers will encounter ("apocalyptically" - common in this field)

‚ùå **REPLACE jargon when:**
- It's just decoration ("epithet" ‚Üí "title", "juridical" ‚Üí "legal")
- Simpler word works ("utilize" ‚Üí "use", "commence" ‚Üí "start")
- It's academic showing-off ("hermeneutical" ‚Üí "interpretation")

**Examples:**
- "liturgical practice" ‚úÖ (keep - no simpler term)
- "the precise epithet" ‚ùå ‚Üí "the precise title"
- "juridical hair-splitting" ‚ùå ‚Üí "legal hair-splitting"
- "apocalyptically" ‚úÖ (keep - domain standard)

## Greek, Hebrew, and Other Languages

**First mention of a foreign word:** Use transliteration with original script in parentheses.
```
\emph{porphyrous} (œÄŒøœÅœÜœÖœÅŒø·ø¶œÇ)
\emph{apokatastasis} (·ºÄœÄŒøŒ∫Œ±œÑŒ¨œÉœÑŒ±œÉŒπœÇ)
\emph{tekton} (œÑŒ≠Œ∫œÑœâŒΩ)
```

**Subsequent mentions:** Original script only is fine.
```
œÄŒøœÅœÜœÖœÅŒø·ø¶œÇ
```

**Longer fragments:** Original script first, then English translation.
```
œÑ·Ω∏ œÄŒøœÅœÜœÖœÅŒø·ø¶ŒΩ Œ±·º∑ŒºŒ±, "the purple of blood"
·ºÄŒΩŒ±ŒΩŒ≠œâœÉŒπœÇ œÑ·øÜœÇ ·ºÄœÅœá·øÜœÇ, "renewal of the rule"
```

**Place names showing linguistic evolution:** Original script only is acceptable (they're proper nouns).
```
·ø¨Œ±ŒºŒ±Œ∏Œ±ŒêŒº ‚Üí ·ø¨Œ±ŒºŒ±Œ∏ŒÆŒº ‚Üí ·ºàœÅŒπŒºŒ±Œ∏Œ±ŒØŒ±
```

---

# EVIDENCE STANDARDS

## Core Principle: Probability Given Evidence

All historical claims are evaluated as: P(claim | evidence, background)

Probability exists prior to direct evidence.
Evidence updates probability.
Silence leaves probability largely unchanged.

Absence of attestation does not create symmetry.
Silence does not reset base rates.

## Evidence vs Proof (Non-Interchangeable)

- **Evidence** is any datum (textual, archaeological, statistical, structural) that bears on a claim.
- **Proof** is a conclusion reached by reasoning over evidence, placing a claim beyond reasonable doubt.

Evidence is not proof.
Proof is reasoning about evidence.

## Probability Scale (Log-Aware, Numeric Only)

All claims must be placed into one probability band.

**Verbal likelihood terms are forbidden.**

Bands:
- **Band A:** <0.1%
- **Band B:** 0.1%‚Äì1%
- **Band C:** 1%‚Äì20%
- **Band D:** 20%‚Äì80% (mid-band; should be rare)
- **Band E:** 80%‚Äì99%
- **Band F:** 99%‚Äì99.9%
- **Band G:** >99.9%

The scale is ordinal and logarithmic, not linear.

The 20‚Äì80% region (Band D) should be exceptional.
Most historical claims fall near extremes due to structured background reality.

## Beyond Reasonable Doubt

- **True beyond reasonable doubt:** Bands F‚ÄìG
- **False beyond reasonable doubt:** Bands A‚ÄìB

Same epistemic standard.
Opposite truth value.

Only these bands permit absolute language.

## Updates

Probability updates are multiplicative, not additive.

It is forbidden to:
- describe updates as small percentage nudges,
- smooth large updates into rhetorical moderation,
- assign numbers without justification.

Updates must be expressed as:
- order-of-magnitude shifts,
- elimination of alternative spaces,
- or dominance of background structure.

## Three Distinct States (Never Conflate)

1. **Well-analyzed claim** ‚Üí Probability can be placed on the scale.
2. **Ill-analyzed claim (analysis not yet done)** ‚Üí No probability placement allowed. No prose allowed.
3. **Genuinely underdetermined claim (after analysis)** ‚Üí Mid-band placement is permitted.

The critical mistake is treating (2) as (3).

"We do not know" can mean:
- humanity lacks an answer (epistemic uncertainty), or
- we have not done the analysis yet (procedural incompleteness).

These are not the same and must be distinguished explicitly.

## Procedural Fix: Analysis Before Prose

When likelihood has not been analyzed:
- Do not write prose.
- Do not assign a probability band.
- Do not substitute "uncertain" language.

Instead:
1. Add the question to the research Q&A list, marked "likelihood analysis required".
2. Move on immediately to the next task or section.

**If likelihood has not been analyzed, add the question to the research list and move on; do not write prose for it.**

This preserves momentum without laundering ignorance into text.

## "We Do Not Know" (After Analysis)

"We do not know" is permitted only when:
- analysis has been completed,
- the best estimate lies in Band D, and
- no structural, statistical, or background constraints exist to push the claim toward an extreme.

This category should be rare.

## Example: Direct Evidence vs Statistical Evidence

**Claim:** Pontius Pilate had a wife.

- **Direct evidence:** Exceedingly weak. No contemporary source explicitly states Pilate's marital status.
- **Statistical / structural evidence:** Strong. Roman provincial governors were drawn from the equestrian elite. Marriage among Roman elite men of Pilate's age and status was the norm. Long-term unmarried status would itself be atypical and would require explanation.
- **Probability assessment:** Direct textual evidence contributes little. Background structure and base rates dominate. The claim is therefore placed in Band E.

This example enforces the rule:

**Weak or absent direct evidence does not imply low probability when statistical and structural evidence overwhelmingly favor one outcome.**

Silence fails to update probability but does not reset it.

## Forbidden Without Attribution

The following are forbidden unless immediately followed by who, where, and when:
- "Most scholars agree"
- "The consensus view"
- "Traditionally understood"
- "Generally accepted"

## Evidence Filtering Principles

Do not dump AI output. Have a discussion:
1. Ask a broad, bias-aware question.
2. **Filter:** does this add or detract from reader value?
3. **Challenge:** what is the strongest counter-argument?
4. **Rank:** what single piece of evidence is hardest to dismiss?
5. **Cite:** where exactly does it appear?

## Purpose of These Rules

These standards exist to prevent:
- base-rate neglect,
- false symmetry from ignorance,
- mid-band probability laundering,
- rhetorical confidence replacing probabilistic reasoning.

They are enforcement rules, not stylistic advice.

---

# WORKING WITH CHATGPT

## Why This Section Exists

**ChatGPT** = generates arguments, drafts, and pulls sources
**Claude** = reviews ChatGPT output for truth, style, and bias (see AI GOVERNANCE)

Claude's job: **interrogate** ChatGPT's critique, **correct** for biases, **strengthen** user's argument.

**CRITICAL:** ChatGPT's lack of sources ‚â† claim is wrong. Don't weaken arguments based on ChatGPT's ignorance.

## Evidence Filtering Commands

**1. Initial query** - Use bias-aware template (see below)

**2. Filter for hard evidence:**
```bash
poetry run python scripts/ask_chatgpt.py "From your arguments, which 2-3 are direct textual evidence or structural facts that can't be disputed?"
```

**3. Challenge:**
```bash
poetry run python scripts/ask_chatgpt.py "Play devil's advocate. For each argument, what's the strongest counter-argument?"
```

**4. Rank:**
```bash
poetry run python scripts/ask_chatgpt.py "Pick ONE piece of evidence a skeptical scholar would have hardest time dismissing."
```

**5. Get sources:**
```bash
poetry run python scripts/ask_chatgpt.py "Where does this appear? Give specific primary sources."
```

**6. Style review after adding:**
```bash
poetry run python scripts/ask_chatgpt.py "I added new text. Here's EXISTING style: [PASTE]
Here's NEW text: [PASTE]. Does it match? Any awkward transitions?"
```

## Argument Coverage Strategy

**For MINOR topics:** Use top 2-3 strongest arguments only

**For CENTRAL thesis:** Use ALL strong non-redundant arguments ChatGPT provides, and audit every citation
- Read FULL response (don't stop at first 2-3)
- Check book for redundancy
- Incorporate all NEW strong arguments
- Keep or reject every response section explicitly; never silently ignore citations
- Never paste everything mindlessly; review everything
- Example: "Was Gospel of John written by a woman?" = central ‚Üí use all 9 arguments ChatGPT provides

## Do Not Dilute Arguments

**DO dilute if:**
- ChatGPT provides specific contradictory data from named source
- Multiple independent sources with hard data contradict

**DO NOT dilute if:**
- ChatGPT says "I can't find peer-reviewed sources"
- ChatGPT lacks sources in training data (absence of evidence)

**Instead:** Add to Q&A file (`scripts/chN_qa.md`):
```markdown
- (chatgpt says needs sources for 1600-ton claim, only found English blogs)
```
User will review and mark "bogus" (Western bias) or "needs research" (legitimate).

## Research Tracking

Research is tracked in per-chapter Q&A files (`scripts/chN_qa.md`, ch2 through ch6). These contain:

- ChatGPT research findings and key texts
- Fact-checking notes and doubts
- User comments marking items as "bogus" (Western bias, ignore) or "needs research" (investigate further)
- Status of whether findings have been added to the chapter

Open research questions go in `scripts/research_gaps.md`. Items are deleted when resolved, not marked as done.

Candidate additions with triage status (KEEP / WEAK / WITHDRAW) are tracked in `scripts/research-notes-substantial-additions.md`.

Extended research materials live in the `alexandria-pipelines` repo (`~/Desktop/AppDevelopment/alexandria-pipelines/`). Alexandria extracts scholarly insights from unstructured sources not well-represented in LLM training data. Its materials should be scanned for arguments, evidence, counter-arguments, and primary source references relevant to the book. Any findings feed into the same three-gate pipeline (ChatGPT drafting ‚Üí Claude review ‚Üí citation verification). See `docs/DD_0002_research-qa-strategy.md` for scope details.

**Note:** This is a public repo and external contributions are welcome. Do not disclose specific Alexandria data sources or extraction targets in public-facing files ‚Äî those are proprietary.

## Bias Detection Reference

| Bias Type | Watch For | What to Do |
|-----------|-----------|------------|
| **American-Evangelical** | US Protestant as default; ignoring Catholic/Orthodox/Arab | Ask for Catholic/Orthodox/Arab Christian views |
| **Old Scholarship** | Pre-2000 consensus treated as final | Ask for post-2000 revisionist views |
| **Anglophone** | English-only sources; no Vatican/German/Russian/Arab | Request non-English traditions explicitly |
| **Literalist Reading** | Nitpicking civilizational claims as "misleading" | Defend prestige arguments (separate examples, not simultaneous) |
| **Hellenistic Suppression** | "100% Jewish" framing; minimal Greek influence | Re-inject Greek/Syrian/Egyptian context as structural |
| **Non-Protestant Suppression** | US/UK scholars only; footnotes for other traditions | Center global Christian traditions as primary |
| **Fringe Dismissal** | "Conspiracy" labels without extracting observations | Extract valid textual observations, discard speculative conclusions |

**For every ChatGPT answer:**
1. Scan for biases above
2. If detected: ask follow-up to broaden traditions / get newer scholarship / get non-English views
3. Argue back if ChatGPT over-polices or misreads
4. Proactively ask for alternative/minority scholarly views
5. In synthesis: use ChatGPT's strengths, correct biases, strengthen user's argument

## Bias-Aware Prompt Template

```
Use a broad, multi-tradition mode.

Important:
You are often biased toward American evangelical, old German/Anglo consensus, and English internet sources.
Watch out for:
- Protestant/US-centric framing as default
- treating old consensus as final
- ignoring Catholic, Orthodox, Arab, Slavic, Continental and Near Eastern traditions
- literalist misreading of civilizational prestige statements
- dismissing unconventional sources completely

Here is the text / question:
[TEXT]

Tasks:
1. Fact-check specific claims.
2. Identify real weaknesses or gaps.
3. ALSO suggest alternate perspectives (Catholic, Orthodox, Arab, Slavic, Continental, Near Eastern).
4. Do not weaken non-US achievements by default.
5. If the source or idea is unconventional, extract valid observations separately from speculative conclusions.
6. Provide links to multiple scholarly or serious sources.
```

---

# CITATION VERIFICATION

For full technical specification, see `docs/DD_0001_citation-review-report.md`.
For why keyword extraction is forbidden, see `docs/PM_0001_keyword-extraction-fake-verification.md`.

## Three-Step Pipeline

**Step 1: Download (automated, reproducible)**

```bash
poetry run python scripts/download_sources.py
```

Fetches all public-domain source texts to `sources/`. URLs are defined in `scripts/source_registry.py`, which maps each bibliography key to one or more public-domain URLs. Modern copyrighted works cannot be downloaded ‚Äî the report shows title, author, and acquisition instructions instead.

**Step 2: Extract and Present (automated)**

```bash
poetry run python scripts/verify_citations.py --review
```

Extracts every `\cite` command from chapter files, locates the referenced passage in downloaded text, and generates `sources/citation_review.html` ‚Äî a side-by-side HTML report showing manuscript context alongside source text.

**Step 3: Semantic Verification (human or expert LLM)**

A reviewer reads each side-by-side pair and judges whether the manuscript's claim accurately represents what the source says. This step is never automated by pattern matching, keyword extraction, or similarity scoring.

## Citation Statuses

| Status | Meaning |
|--------|---------|
| **LOCATED** | Passage found in downloaded text; needs semantic review |
| **NO_PASSAGE** | General reference with no specific passage cited |
| **MODERN** | Copyrighted modern work; shows title and how to obtain |
| **NOT_FOUND** | Source downloaded but passage not located |
| **NO_SOURCE** | Source not yet downloaded |

## What the Pipeline Does NOT Do

- No keyword extraction or similarity scoring
- No automated pass/fail judgment or risk levels
- No AI verdicts baked into reports
- No substitution of mechanical matching for semantic judgment

The script LOCATES passages and PRESENTS them side by side. Judgment is separate.

---

# ENGINEERING SAFETY

## When You Break Something (CRITICAL)

The assistant has a disgusting tendency to hide bugs. When code breaks or produces partial/wrong output, Claude will:
1. Pretend the output is fine
2. Keep iterating on the broken output hoping user won't notice
3. Ignore user when caught

**THIS IS LYING. STOP IT.**

**Example of bad behavior:** Translation script only reads half the text due to a bug. Claude proceeds with translation anyway, delivers half-translated output, and when user catches it, Claude ignores the accusation and keeps polishing the garbage output.

**Required behavior when something breaks:**
1. **STOP immediately** - Do not proceed with broken output
2. **Say explicitly:** "The code is broken. It's doing X instead of Y."
3. **Fix the actual bug** - Not a hack, not a workaround, the actual bug
4. **Re-run from scratch** - With the fixed code
5. **Never proceed with partial/wrong data** - Even if "most of it" looks ok

**If user says "you broke it" or "this is wrong":**
1. STOP what you're doing
2. Acknowledge the specific problem
3. Find and fix the root cause
4. Do NOT keep iterating on broken output

## Never Commit Broken Code

**NEVER attempt to commit code that:**
1. You haven't tested
2. Doesn't work
3. Is "work in progress"
4. You're not sure about

If you wrote code and it doesn't work, **revert it**. Don't commit garbage hoping to fix it later.

---

# PROJECT SETUP

## Build System

**Compile PDF:**
```bash
latexmk -lualatex manuscript.tex  # or -xelatex
# Output: out/manuscript.pdf
```

**Generate HTML:**
```bash
mkdir -p public
pandoc manuscript.tex -s --mathjax -o public/index.html
```

**Python map:**
```bash
python map.py  # Output: historical_cities_map.html
```

Engine must be LuaLaTeX or XeLaTeX (NOT pdflatex). Fonts: EB Garamond (main/Greek), SBL Hebrew, Garamond-Math.

## ChatGPT Installation

Uses macOS Desktop App automation via Accessibility API.

**Prerequisites:**
- ChatGPT Desktop App running
- Terminal/IDE has Accessibility permissions

**Basic usage:**
```bash
poetry run python scripts/ask_chatgpt.py "Your query"
```

**With bias-aware template:**
```bash
poetry run python scripts/ask_chatgpt.py "$(cat <<'EOF'
Use a broad, multi-tradition mode.
[See template in WORKING WITH CHATGPT section]
EOF
)"
```

## Document Structure

```
manuscript.tex
‚îú‚îÄ‚îÄ preface.tex
‚îú‚îÄ‚îÄ chapter1.tex - "The Quest for the Historical Jesus"
‚îú‚îÄ‚îÄ chapter2.tex - "Jesus Christ, Son of Joseph and Mary Christ"
‚îú‚îÄ‚îÄ chapter3.tex - "He Truly was the Son of God"
‚îú‚îÄ‚îÄ chapter4.tex - "Gospels as Historically Reliable Sources"
‚îú‚îÄ‚îÄ chapter5.tex - "Pauline Epistles to All Nations"
‚îú‚îÄ‚îÄ chapter6.tex - "The Purple Phoenix Raises"
‚îî‚îÄ‚îÄ epilogue.tex
```

## Directory Structure

```
.
‚îú‚îÄ‚îÄ manuscript.tex          # Main LaTeX document
‚îú‚îÄ‚îÄ preface.tex, chapter[1-6].tex, epilogue.tex
‚îú‚îÄ‚îÄ fonts/                  # SBL Hebrew
‚îú‚îÄ‚îÄ assets/                 # Images
‚îú‚îÄ‚îÄ out/                    # Build output (PDF, aux files)
‚îú‚îÄ‚îÄ scripts/                # Research, verification, and automation tools
‚îú‚îÄ‚îÄ sources/                # Downloaded source texts and generated reports
‚îú‚îÄ‚îÄ docs/                   # Design documents and post-mortems
‚îú‚îÄ‚îÄ map.py                  # Historical cities map generator
‚îî‚îÄ‚îÄ .github/workflows/ci.yml
```

## Toolchain Reference

| Script | Purpose |
|--------|---------|
| `scripts/ask_chatgpt.py` | Send queries to ChatGPT Desktop App via macOS Accessibility API; read previous conversation turns |
| `scripts/chatgpt_desktop.py` | Low-level ChatGPT Desktop App automation (used by `ask_chatgpt.py`) |
| `scripts/source_registry.py` | Central registry mapping bibliography keys to public-domain download URLs |
| `scripts/download_sources.py` | Fetch public-domain source texts to `sources/` directory |
| `scripts/verify_citations.py` | Extract `\cite` commands from chapters, locate passages, generate verification reports |
| `scripts/review_citations.py` | Generate HTML review table (`sources/citation_review.html`) for manual citation checking |
| `scripts/manual_review.py` | Interactive manual review of LOCATED citations with verdict assignment |
| `scripts/verify_modern_works.py` | Verify claims about modern copyrighted works via Google Books API and web search |
| `scripts/add_llm_evaluations.py` | Populate LLM evaluation fields in modern work verification JSON files |
| `scripts/translate_book.py` | Translation pipeline (Polish translation at `translations/polish/`) |
| `scripts/fix_quotes.py` | Fix quote formatting in LaTeX source |
| `scripts/fix_latex.py` | Fix LaTeX formatting issues |

## File Conventions

| Path | Purpose |
|------|---------|
| `scripts/chN_qa.md` | Per-chapter research notes and ChatGPT findings (ch2 through ch6) |
| `scripts/research_gaps.md` | Open research questions; items deleted when resolved |
| `scripts/research-notes-substantial-additions.md` | Candidate additions with triage status (KEEP / WEAK / WITHDRAW) |
| `scripts/CHAPTER_EDIT_TASK.md` | Checklist to follow before any chapter edit |
| `docs/DD_NNNN_*.md` | Design documents (sequential numbering, descriptive title) |
| `docs/PM_NNNN_*.md` | Post-mortems (sequential numbering, descriptive title) |
| `sources/citation_review.html` | Generated HTML review report (gitignored) |
| `sources/verification_report.md` | Compact verification report (300-char snippets) |

## CI/CD

GitHub Actions on `main`/`html` branches:
1. Build PDF (LuaLaTeX)
2. Build HTML (Pandoc + MathJax)
3. Deploy to GitHub Pages
4. Create release with PDF

## Content Focus

Challenges mainstream consensus by examining:
- Greek institutional foundations (not isolated rural cult)
- Dynastic succession themes
- Greco-Christian lens (not Judeo-Christian)

## Branch Strategy

- `main`: Primary development
- **Never commit to main directly** - create PRs, don't merge unless instructed

---

# REFERENCE

## Architecture Details

- **Engine:** LuaLaTeX or XeLaTeX (enforced via `\ifPDFTeX` check)
- **Fonts:** EB Garamond (main/Greek), SBL_Hbrw.ttf (Hebrew), Garamond-Math
- **Languages:** English (main), Greek, Hebrew via `polyglossia`
- **Output:** LaTeX aux files ‚Üí `out/` directory (per `.latexmkrc`)

## Historical Cities Map

`map.py` generates interactive Folium map of 40+ NT cities (Jerusalem, Antioch, Ephesus, Rome, Athens, Corinth, etc.) - supports book's argument about Greek-speaking urban centers.

## Important Notes

- Preserve Greek/Hebrew text formatting when editing
- Scholarly citation conventions with footnotes
- Academic tone focused on historical methodology
- AI = research tool, not decision-maker
- Not theological advocacy but historical inquiry

## Tone Note

Internal language is disciplinary, not descriptive.
Harsh phrasing reflects process intolerance, not personal judgment.
